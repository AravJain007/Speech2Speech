{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:36:38.369101Z","iopub.status.busy":"2024-08-27T13:36:38.368739Z","iopub.status.idle":"2024-08-27T13:37:30.654888Z","shell.execute_reply":"2024-08-27T13:37:30.653676Z","shell.execute_reply.started":"2024-08-27T13:36:38.369074Z"},"trusted":true},"outputs":[],"source":["!pip install git+https://github.com/huggingface/transformers.git "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-27T13:37:30.657241Z","iopub.status.busy":"2024-08-27T13:37:30.656941Z","iopub.status.idle":"2024-08-27T13:38:20.160879Z","shell.execute_reply":"2024-08-27T13:38:20.159697Z","shell.execute_reply.started":"2024-08-27T13:37:30.657215Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["pip install git+https://github.com/huggingface/parler-tts.git"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-27T13:39:30.394793Z","iopub.status.busy":"2024-08-27T13:39:30.393689Z","iopub.status.idle":"2024-08-27T13:39:44.713434Z","shell.execute_reply":"2024-08-27T13:39:44.712330Z","shell.execute_reply.started":"2024-08-27T13:39:30.394750Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install transformers torch accelerate bitsandbytes onnxruntime"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:38:38.060589Z","iopub.status.busy":"2024-08-27T13:38:38.060267Z","iopub.status.idle":"2024-08-27T13:39:01.287174Z","shell.execute_reply":"2024-08-27T13:39:01.285990Z","shell.execute_reply.started":"2024-08-27T13:38:38.060561Z"},"trusted":true},"outputs":[],"source":["!pip install --upgrade protobuf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:39:57.090277Z","iopub.status.busy":"2024-08-27T13:39:57.089443Z","iopub.status.idle":"2024-08-27T13:39:57.095082Z","shell.execute_reply":"2024-08-27T13:39:57.094086Z","shell.execute_reply.started":"2024-08-27T13:39:57.090237Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration, AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:39:57.365174Z","iopub.status.busy":"2024-08-27T13:39:57.364371Z","iopub.status.idle":"2024-08-27T13:39:58.089894Z","shell.execute_reply":"2024-08-27T13:39:58.088951Z","shell.execute_reply.started":"2024-08-27T13:39:57.365145Z"},"trusted":true},"outputs":[],"source":["# Load the VAD model\n","vad_model, vad_utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n","                                  model='silero_vad',\n","                                  force_reload=True,\n","                                  onnx=True)\n","get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks = vad_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:39:59.129905Z","iopub.status.busy":"2024-08-27T13:39:59.129175Z","iopub.status.idle":"2024-08-27T13:40:05.094181Z","shell.execute_reply":"2024-08-27T13:40:05.093302Z","shell.execute_reply.started":"2024-08-27T13:39:59.129870Z"},"trusted":true},"outputs":[],"source":["# Load the Whisper model for Speech-to-Text\n","whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\", \n","                                                            device_map=\"auto\",\n","                                                            load_in_8bit=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:44:31.840088Z","iopub.status.busy":"2024-08-27T13:44:31.839664Z","iopub.status.idle":"2024-08-27T13:45:07.632876Z","shell.execute_reply":"2024-08-27T13:45:07.632047Z","shell.execute_reply.started":"2024-08-27T13:44:31.840058Z"},"trusted":true},"outputs":[],"source":["# Load the LLaMA model for generating responses\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","model_name = \"microsoft/Phi-3.5-mini-instruct\"  # Phi-3.5 is not publicly available, so we'll use Phi-2 as an example\n","    \n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","    \n","# Load the model with 4-bit quantization\n","llm_model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        device_map=\"auto\",\n","        trust_remote_code=True,\n","        load_in_4bit=True,\n","        max_memory={0: \"15GB\"}  # Adjust this based on your Colab's GPU memory\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:40:35.635858Z","iopub.status.busy":"2024-08-27T13:40:35.635391Z","iopub.status.idle":"2024-08-27T13:41:53.225240Z","shell.execute_reply":"2024-08-27T13:41:53.224402Z","shell.execute_reply.started":"2024-08-27T13:40:35.635820Z"},"trusted":true},"outputs":[],"source":["from parler_tts import ParlerTTSForConditionalGeneration\n","from transformers import AutoTokenizer, set_seed\n","parler_model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-expresso\").to(\"cuda:0\")\n","parler_tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-expresso\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:55:04.122530Z","iopub.status.busy":"2024-08-27T13:55:04.122140Z","iopub.status.idle":"2024-08-27T13:55:04.137029Z","shell.execute_reply":"2024-08-27T13:55:04.136181Z","shell.execute_reply.started":"2024-08-27T13:55:04.122500Z"},"trusted":true},"outputs":[],"source":["def vad_and_split(audio_file):\n","    \"\"\"Apply VAD and return only the speech segments\"\"\"\n","    wav = read_audio(audio_file, sampling_rate=16000)\n","    speech_timestamps = get_speech_timestamps(wav, vad_model, sampling_rate=16000)\n","    speech_chunks = collect_chunks(speech_timestamps, wav)\n","    return speech_chunks\n","\n","\n","def transcribe(speech_chunk):\n","    \"\"\"Convert a speech chunk to text\"\"\"\n","    inputs = whisper_processor(torch.tensor(speech_chunk,dtype = torch.float16), return_tensors=\"pt\", sampling_rate=16000,).to(\"cuda:0\")\n","    generated_ids = whisper_model.generate(torch.tensor(inputs.input_features,dtype = torch.float16))\n","    transcription = whisper_processor.batch_decode(generated_ids, skip_special_tokens=True)\n","    print(transcription)\n","    return transcription[0]\n","\n","\n","from IPython.display import Markdown\n","\n","\n","def generate_response(text):\n","    prefix = \"\"\"<|system|> You provide only one-line answers: concise, precise, and accurate. If the query is long, first summarize, then respond.<|end|>\n","    <|user|>\n","    \"\"\"\n","    postfix = \"\"\"\n","<|assistant|> \"\"\"\n","    \n","    full_prompt = prefix + text + postfix\n","    \n","    inputs = tokenizer(full_prompt, return_tensors=\"pt\", max_length=4096, truncation=True).to(llm_model.device)\n","    \n","    with torch.no_grad():\n","        outputs = llm_model.generate(\n","            inputs.input_ids, \n","            max_new_tokens=64,\n","            do_sample=True,\n","            top_p=0.9,\n","            temperature=0.1\n","        )\n","    \n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    response_cleaned = response[len(full_prompt):].strip()\n","    \n","    return response_cleaned\n","\n","\n","def synthesize_speech(text, output_file=\"output.wav\"):\n","    import soundfile as sf\n","    \"\"\"Convert the generated text response to speech\"\"\"\n","    \n","    description = \"Talia speaks happy tone with emphasis and high quality audio with zero errors.\"\n","\n","    input_ids = parler_tokenizer(description, return_tensors=\"pt\").input_ids.to(\"cuda:0\")\n","    prompt_input_ids = parler_tokenizer(text, return_tensors=\"pt\").input_ids.to(\"cuda:0\")\n","\n","    generation = parler_model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n","    audio_arr = generation.cpu().numpy().squeeze()\n","    sf.write(\"parler_tts_out.wav\", audio_arr, parler_model.config.sampling_rate)\n","    return output_file\n","\n","\n","def process_audio_pipeline(audio_file):\n","    \"\"\"Complete pipeline from audio input to speech output\"\"\"\n","    # Step 1: Apply VAD and get relevant speech chunks\n","    speech_chunks = vad_and_split(audio_file)\n","    \n","    # Process chunk through the Speech-to-Text model\n","    full_transcription = transcribe(speech_chunks)\n","\n","    # Step 2: Generate a response using LLaMA model\n","    response = generate_response(full_transcription.strip())\n","\n","    # Step 3: Convert the response to speech and save the file\n","    output_file = synthesize_speech(response)\n","\n","    return output_file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T13:55:04.609454Z","iopub.status.busy":"2024-08-27T13:55:04.608914Z","iopub.status.idle":"2024-08-27T13:55:27.447328Z","shell.execute_reply":"2024-08-27T13:55:27.446345Z","shell.execute_reply.started":"2024-08-27T13:55:04.609425Z"},"trusted":true},"outputs":[],"source":["# Usage:\n","import time\n","audio_file_location = \"/kaggle/input/lizmotorsinternshiptest/Recording.wav\"\n","start = time.time()\n","output_audio = process_audio_pipeline(audio_file_location)\n","print(f\"Output speech file saved to: {output_audio}, in time {time.time()-start}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5568452,"sourceId":9210169,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
